{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIP Labor",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartonJToth/DIP_Labor/blob/master/DIP_Labor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiXP0xuopiRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Based on https://github.com/DmitryUlyanov/deep-image-prior/blob/master/inpainting.ipynb\n",
        "\n",
        "!pip3 install torch torchvision \n",
        "!pip install matplotlib\n",
        "!pip3 install Pillow==4.2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4WJd3QBqHfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgjZEJlkqlM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://cg.iit.bme.hu/~tmarton/deeplearning/DIPLabData.zip\n",
        "!unzip -qq DIPLabData.zip\n",
        "!rm DIPLabData.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9mtMPlsq3yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imsize = -1\n",
        "dim_div_by = 64\n",
        "\n",
        "img_path  = 'DIPLabData/kate.png'\n",
        "mask_path = 'DIPLabData/kate_mask.png'\n",
        "\n",
        "dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qMjmjWOrqAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "def get_noise(input_depth, spatial_size, noise_type='u', var=1./10):\n",
        "\n",
        "    if isinstance(spatial_size, int):\n",
        "        spatial_size = (spatial_size, spatial_size)\n",
        "        \n",
        "      \n",
        "    shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
        "    net_input = torch.zeros(shape)\n",
        "\n",
        "    net_input.uniform_()\n",
        "    net_input *= var            \n",
        "        \n",
        "    return net_input\n",
        "\n",
        "def pil_to_np(img_PIL):\n",
        "  '''Converts image in PIL format to np.array.\n",
        "\n",
        "  From W x H x C [0...255] to C x W x H [0..1]\n",
        "  '''\n",
        "  ar = np.array(img_PIL)\n",
        "\n",
        "  if len(ar.shape) == 3:\n",
        "    ar = ar.transpose(2,0,1)\n",
        "  else:\n",
        "    ar = ar[None, ...]\n",
        "\n",
        "  return ar.astype(np.float32) / 255.\n",
        "\n",
        "def get_image(path, imsize=-1):\n",
        "  \n",
        "    img = img = Image.open(path)\n",
        "\n",
        "    if isinstance(imsize, int):\n",
        "        imsize = (imsize, imsize)\n",
        "\n",
        "    if imsize[0]!= -1 and img.size != imsize:\n",
        "        if imsize[0] > img.size[0]:\n",
        "            img = img.resize(imsize, Image.BICUBIC)\n",
        "        else:\n",
        "            img = img.resize(imsize, Image.ANTIALIAS)\n",
        "\n",
        "    img_np = pil_to_np(img)\n",
        "\n",
        "    return img, img_np\n",
        "  \n",
        "  \n",
        "def crop_image(img, d=32):\n",
        "    '''Make dimensions divisible by `d`'''\n",
        "\n",
        "    new_size = (img.size[0] - img.size[0] % d, \n",
        "                img.size[1] - img.size[1] % d)\n",
        "\n",
        "    bbox = [\n",
        "            int((img.size[0] - new_size[0])/2), \n",
        "            int((img.size[1] - new_size[1])/2),\n",
        "            int((img.size[0] + new_size[0])/2),\n",
        "            int((img.size[1] + new_size[1])/2),\n",
        "    ]\n",
        "\n",
        "    img_cropped = img.crop(bbox)\n",
        "    return img_cropped\n",
        "  \n",
        "def plot_image_grid(images_np, nrow =8, factor=1, interpolation='lanczos'):\n",
        "\n",
        "  n_channels = max(x.shape[0] for x in images_np)\n",
        "  assert (n_channels == 3) or (n_channels == 1), \"images should have 1 or 3 channels\"\n",
        "\n",
        "  images_np = [x if (x.shape[0] == n_channels) else np.concatenate([x, x, x], axis=0) for x in images_np]\n",
        "  \n",
        "  images_torch = [torch.from_numpy(x) for x in images_np]\n",
        "  torch_grid = torchvision.utils.make_grid(images_torch, nrow)\n",
        "\n",
        "  grid = torch_grid.numpy()\n",
        "\n",
        "  plt.figure(figsize=(len(images_np) + factor, 12 + factor))\n",
        "\n",
        "  if images_np[0].shape[0] == 1:\n",
        "      plt.imshow(grid[0], cmap='gray', interpolation=interpolation)\n",
        "  else:\n",
        "      plt.imshow(grid.transpose(1, 2, 0), interpolation=interpolation)\n",
        "      \n",
        "  plt.show()\n",
        "\n",
        "  return grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIc8BpMgrWHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_pil, img_np = get_image(img_path, imsize)\n",
        "img_mask_pil, img_mask_np = get_image(mask_path, imsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTCVpNKTsvcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_mask_pil = crop_image(img_mask_pil, dim_div_by)\n",
        "img_pil      = crop_image(img_pil,      dim_div_by)\n",
        "\n",
        "img_np      = pil_to_np(img_pil)\n",
        "img_mask_np = pil_to_np(img_mask_pil)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuQZPZWeRDAT",
        "colab_type": "text"
      },
      "source": [
        "TODO: saját maszk készítése, meddig képes a részleteket összerakni, vagy zaj hozzákeverése"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyt4TwbdszPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_image_grid([img_np, img_mask_np, img_mask_np*img_np], 3,11);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdmw8umQuZAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def add_module(self, module):\n",
        "    self.add_module(str(len(self) + 1), module)\n",
        "    \n",
        "torch.nn.Module.add = add_module\n",
        "\n",
        "def bn(num_features):\n",
        "    return nn.BatchNorm2d(num_features)\n",
        "  \n",
        "def conv(in_f, out_f, kernel_size, stride=1, bias=True, pad='zero', downsample_mode='stride'):\n",
        "    downsampler = None\n",
        "    if stride != 1 and downsample_mode != 'stride':\n",
        "\n",
        "        if downsample_mode == 'avg':\n",
        "            downsampler = nn.AvgPool2d(stride, stride)\n",
        "        elif downsample_mode == 'max':\n",
        "            downsampler = nn.MaxPool2d(stride, stride)\n",
        "        elif downsample_mode  in ['lanczos2', 'lanczos3']:\n",
        "            downsampler = Downsampler(n_planes=out_f, factor=stride, kernel_type=downsample_mode, phase=0.5, preserve_size=True)\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "        stride = 1\n",
        "\n",
        "    padder = None\n",
        "    to_pad = int((kernel_size - 1) / 2)\n",
        "    if pad == 'reflection':\n",
        "        padder = nn.ReflectionPad2d(to_pad)\n",
        "        to_pad = 0\n",
        "  \n",
        "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
        "\n",
        "\n",
        "    layers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  \n",
        "def act(act_fun = 'LeakyReLU'):\n",
        "\n",
        "  if isinstance(act_fun, str):\n",
        "    if act_fun == 'LeakyReLU':\n",
        "      return nn.LeakyReLU(0.2, inplace=True)\n",
        "    elif act_fun == 'Swish':\n",
        "      return Swish()\n",
        "    elif act_fun == 'ELU':\n",
        "      return nn.ELU()\n",
        "    elif act_fun == 'none':\n",
        "      return nn.Sequential()\n",
        "    else:\n",
        "      assert False\n",
        "  else:\n",
        "    return act_fun()\n",
        "\n",
        "class Concat(nn.Module):\n",
        "  def __init__(self, dim, *args):\n",
        "    super(Concat, self).__init__()\n",
        "    self.dim = dim\n",
        "\n",
        "    for idx, module in enumerate(args):\n",
        "      self.add_module(str(idx), module)\n",
        "\n",
        "  def forward(self, input):\n",
        "    inputs = []\n",
        "    for module in self._modules.values():\n",
        "      inputs.append(module(input))\n",
        "\n",
        "    inputs_shapes2 = [x.shape[2] for x in inputs]\n",
        "    inputs_shapes3 = [x.shape[3] for x in inputs]        \n",
        "\n",
        "    if np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(np.array(inputs_shapes3) == min(inputs_shapes3)):\n",
        "      inputs_ = inputs\n",
        "    else:\n",
        "      target_shape2 = min(inputs_shapes2)\n",
        "      target_shape3 = min(inputs_shapes3)\n",
        "\n",
        "      inputs_ = []\n",
        "      for inp in inputs: \n",
        "        diff2 = (inp.size(2) - target_shape2) // 2 \n",
        "        diff3 = (inp.size(3) - target_shape3) // 2 \n",
        "        inputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
        "\n",
        "    return torch.cat(inputs_, dim=self.dim)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._modules)\n",
        "\n",
        "def skip(\n",
        "        num_input_channels=2, num_output_channels=3, \n",
        "        num_channels_down=[16, 32, 64, 128, 128], num_channels_up=[16, 32, 64, 128, 128], num_channels_skip=[4, 4, 4, 4, 4], \n",
        "        filter_size_down=3, filter_size_up=3, filter_skip_size=1,\n",
        "        need_sigmoid=True, need_bias=True, \n",
        "        pad='zero', upsample_mode='nearest', downsample_mode='stride', act_fun='LeakyReLU', \n",
        "        need1x1_up=True):\n",
        "    \"\"\"Assembles encoder-decoder with skip connections.\n",
        "\n",
        "    Arguments:\n",
        "        act_fun: Either string 'LeakyReLU|Swish|ELU|none' or module (e.g. nn.ReLU)\n",
        "        pad (string): zero|reflection (default: 'zero')\n",
        "        upsample_mode (string): 'nearest|bilinear' (default: 'nearest')\n",
        "        downsample_mode (string): 'stride|avg|max|lanczos2' (default: 'stride')\n",
        "\n",
        "    \"\"\"\n",
        "    assert len(num_channels_down) == len(num_channels_up) == len(num_channels_skip)\n",
        "\n",
        "    n_scales = len(num_channels_down) \n",
        "\n",
        "    if not (isinstance(upsample_mode, list) or isinstance(upsample_mode, tuple)) :\n",
        "        upsample_mode   = [upsample_mode]*n_scales\n",
        "\n",
        "    if not (isinstance(downsample_mode, list)or isinstance(downsample_mode, tuple)):\n",
        "        downsample_mode   = [downsample_mode]*n_scales\n",
        "    \n",
        "    if not (isinstance(filter_size_down, list) or isinstance(filter_size_down, tuple)) :\n",
        "        filter_size_down   = [filter_size_down]*n_scales\n",
        "\n",
        "    if not (isinstance(filter_size_up, list) or isinstance(filter_size_up, tuple)) :\n",
        "        filter_size_up   = [filter_size_up]*n_scales\n",
        "\n",
        "    last_scale = n_scales - 1 \n",
        "\n",
        "    cur_depth = None\n",
        "\n",
        "    model = nn.Sequential()\n",
        "    model_tmp = model\n",
        "\n",
        "    input_depth = num_input_channels\n",
        "    for i in range(len(num_channels_down)):\n",
        "\n",
        "        deeper = nn.Sequential()\n",
        "        skip = nn.Sequential()\n",
        "\n",
        "        if num_channels_skip[i] != 0:\n",
        "            model_tmp.add(Concat(1, skip, deeper))\n",
        "        else:\n",
        "            model_tmp.add(deeper)\n",
        "        \n",
        "        model_tmp.add(bn(num_channels_skip[i] + (num_channels_up[i + 1] if i < last_scale else num_channels_down[i])))\n",
        "\n",
        "        if num_channels_skip[i] != 0:\n",
        "            skip.add(conv(input_depth, num_channels_skip[i], filter_skip_size, bias=need_bias, pad=pad))\n",
        "            skip.add(bn(num_channels_skip[i]))\n",
        "            skip.add(act(act_fun))\n",
        "            \n",
        "        # skip.add(Concat(2, GenNoise(nums_noise[i]), skip_part))\n",
        "\n",
        "        deeper.add(conv(input_depth, num_channels_down[i], filter_size_down[i], 2, bias=need_bias, pad=pad, downsample_mode=downsample_mode[i]))\n",
        "        deeper.add(bn(num_channels_down[i]))\n",
        "        deeper.add(act(act_fun))\n",
        "\n",
        "        deeper.add(conv(num_channels_down[i], num_channels_down[i], filter_size_down[i], bias=need_bias, pad=pad))\n",
        "        deeper.add(bn(num_channels_down[i]))\n",
        "        deeper.add(act(act_fun))\n",
        "\n",
        "        deeper_main = nn.Sequential()\n",
        "\n",
        "        if i == len(num_channels_down) - 1:\n",
        "            # The deepest\n",
        "            k = num_channels_down[i]\n",
        "        else:\n",
        "            deeper.add(deeper_main)\n",
        "            k = num_channels_up[i + 1]\n",
        "\n",
        "        deeper.add(nn.Upsample(scale_factor=2, mode=upsample_mode[i]))\n",
        "\n",
        "        model_tmp.add(conv(num_channels_skip[i] + k, num_channels_up[i], filter_size_up[i], 1, bias=need_bias, pad=pad))\n",
        "        model_tmp.add(bn(num_channels_up[i]))\n",
        "        model_tmp.add(act(act_fun))\n",
        "\n",
        "\n",
        "        if need1x1_up:\n",
        "            model_tmp.add(conv(num_channels_up[i], num_channels_up[i], 1, bias=need_bias, pad=pad))\n",
        "            model_tmp.add(bn(num_channels_up[i]))\n",
        "            model_tmp.add(act(act_fun))\n",
        "\n",
        "        input_depth = num_channels_down[i]\n",
        "        model_tmp = deeper_main\n",
        "\n",
        "    model.add(conv(num_channels_up[0], num_output_channels, 1, bias=need_bias, pad=pad))\n",
        "    if need_sigmoid:\n",
        "        model.add(nn.Sigmoid())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9z72rpEuKcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_depth = 32\n",
        "LR = 0.01 \n",
        "num_iter = 6001\n",
        "param_noise = False\n",
        "show_every = 50\n",
        "figsize = 5\n",
        "reg_noise_std = 0.03\n",
        "pad = 'reflection' # 'zero'\n",
        "\n",
        "net = skip(input_depth, img_np.shape[0], \n",
        "           num_channels_down = [128] * 5,\n",
        "           num_channels_up =   [128] * 5,\n",
        "           num_channels_skip =    [128] * 5,  \n",
        "           filter_size_up = 3, filter_size_down = 3, \n",
        "           upsample_mode='nearest', filter_skip_size=1,\n",
        "           need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "\n",
        "net = net.type(dtype)\n",
        "net_input = get_noise(input_depth, img_np.shape[1:]).type(dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANS3JsK-zprU",
        "colab_type": "code",
        "outputId": "66609fcc-3a13-4798-e390-1609f2e9b64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute number of parameters\n",
        "s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
        "print ('Number of params: %d' % s)\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "\n",
        "img_var = torch.from_numpy(img_np)[None, :].type(dtype)\n",
        "mask_var = torch.from_numpy(img_mask_np)[None, :].type(dtype)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of params: 3002627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhOQNKzz0pdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize(parameters, closure, LR, num_iter):\n",
        "\n",
        "  \n",
        "  print('Starting optimization with ADAM')\n",
        "  optimizer = torch.optim.Adam(parameters, lr=LR)\n",
        "\n",
        "  for j in range(num_iter):\n",
        "    optimizer.zero_grad()\n",
        "    closure()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULfh-cViz6XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "i = 0\n",
        "def closure():\n",
        "    \n",
        "    global i\n",
        "    \n",
        "    if param_noise:\n",
        "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
        "            n = n + n.detach().clone().normal_() * n.std() / 50\n",
        "    \n",
        "    net_input = net_input_saved\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "        \n",
        "        \n",
        "    out = net(net_input)\n",
        "   \n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "        \n",
        "    print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
        "    if  i % show_every == 0:\n",
        "        out_np = out.detach().cpu().numpy()[0]\n",
        "        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
        "        \n",
        "    i += 1\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxfJ_JIbz-Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "\n",
        "\n",
        "optimize(net.parameters(), closure, LR, num_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}